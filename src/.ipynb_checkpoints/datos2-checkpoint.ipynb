{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplodatos Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present this peace of code to create the baseline for the competition, and as an example of how to deal with these kind of problems. The main goals are that you:\n",
    "\n",
    "1. Learn\n",
    "1. Try different models and see which one fits the best the given data\n",
    "1. Get a higher score than the given one in the current baseline example\n",
    "1. Try to get the highest score in the class :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the *original* dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data_fname, test_data_fname):\n",
    "    df_train = pd.read_csv(train_data_fname)\n",
    "    df_train['is_train_set'] = 1\n",
    "    df_test = pd.read_csv(test_data_fname)\n",
    "    df_test['is_train_set'] = 0\n",
    "    \n",
    "    # Comienzo con los datos de TRAIN\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # Elimino los datos que tienen Nan en el Department Description\n",
    "    clean_df = df_train.dropna(subset=['DepartmentDescription'])\n",
    "\n",
    "    # Los datos que tienen Nan en Upc son todos de Pharmacy RX\n",
    "    # Luego los completo con esos valores, obtenidos por inspecci√≥n\n",
    "    clean_df.loc[clean_df.Upc.isna(), \"FinelineNumber\"] = 4822\n",
    "    clean_df.loc[clean_df.Upc.isna(), \"Upc\"] = 30169183702\n",
    "    \n",
    "    unique_tt = df_train.TripType.unique()\n",
    "    lista_df = []\n",
    "    for i in unique_tt:\n",
    "        iterator = clean_df[clean_df.TripType == i]\n",
    "        max = iterator.Upc.value_counts().idxmax()\n",
    "        iterator.Upc = max\n",
    "        lista_df.append(iterator)\n",
    "\n",
    "    df_total = pd.concat(lista_df)\n",
    "    df_total = df_total.drop([\"FinelineNumber\"], axis=1)\n",
    "    y = df_total.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).max().TripType\n",
    "\n",
    "    df_total = df_total.drop(\"TripType\", axis=1)\n",
    "    \n",
    "    # VISITNUMBER, DEPARTMENT, UPC, WEEKDAY\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    df_test.loc[df_test.DepartmentDescription.isna(), \"Upc\"] = 0\n",
    "    df_test.loc[df_test.Upc.isna(), \"Upc\"] = 30169183702\n",
    "    unique_vn = df_test.VisitNumber.unique()\n",
    "    lista_df = []\n",
    "    for i in unique_vn:\n",
    "        iterator = df_test[df_test.VisitNumber == i]\n",
    "        max = iterator.Upc.max()\n",
    "        iterator.Upc = max\n",
    "        lista_df.append(iterator)\n",
    "\n",
    "    test_total = pd.concat(lista_df)\n",
    "    \n",
    "    test_total = test_total.drop([\"FinelineNumber\"], axis=1)\n",
    "    \n",
    "    # VISITNUMBER, DEPARTMENT, UPC, WEEKDAY\n",
    "    \n",
    "    temp_concat = pd.concat([df_total, test_total])\n",
    "    temp_concat = pd.get_dummies(temp_concat, columns=[\"DepartmentDescription\"], dummy_na=True)\n",
    "    temp_concat = temp_concat.groupby([\"VisitNumber\", \"Weekday\", \"Upc\"], as_index=False).sum()\n",
    "    \n",
    "    temp_concat = pd.get_dummies(temp_concat, columns=[\"Weekday\"], dummy_na=True)\n",
    "    \n",
    "    df_train = temp_concat[temp_concat.is_train_set != 0]\n",
    "    df_test = temp_concat[temp_concat.is_train_set == 0]\n",
    "\n",
    "    X = df_train.drop([\"is_train_set\"], axis=1)\n",
    "    yy = None\n",
    "    XX = df_test.drop([\"is_train_set\"], axis=1)\n",
    "\n",
    "\n",
    "    return X, y, XX, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\503161912\\Miniconda3\\envs\\mentoria\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\503161912\\Miniconda3\\envs\\mentoria\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'df' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-57a01a3beba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/train.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"../data/test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-df6db9448b82>\u001b[0m in \u001b[0;36mtransform_data\u001b[1;34m(train_data_fname, test_data_fname)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mdf_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlista_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"FinelineNumber\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TripType\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'df' referenced before assignment"
     ]
    }
   ],
   "source": [
    "X, y, XX, yy = transform_data(\"../data/train.csv\", \"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training dataset into train and \"validation\" \n",
    "# (we won't be using validation set in this example, because of the cross-validation;\n",
    "# but it could be useful for you depending on your approach)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results dataframe is used to store the computed results\n",
    "results = pd.DataFrame(columns=('clf', 'best_acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use a DesicionTree to classify and GridSearch to determine the parameters\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree_param = {'criterion':('gini', 'entropy'), 'min_samples_leaf':(1, 2, 5),\n",
    "              'min_samples_split':(2, 3, 5, 10, 50, 100)}\n",
    "tree = DT(random_state=42)\n",
    "tree_clf = GridSearchCV(tree, tree_param, cv=3, scoring='accuracy') #scoring='balanced_accuracy')\n",
    "tree_clf.fit(X_train, y_train)\n",
    "best_tree_clf = tree_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree accuracy:  0.6304134697357204\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=100,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=42, splitter='best')\n",
      "The best classifier so far is: \n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=100,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=42, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print('Best Decision Tree accuracy: ', tree_clf.best_score_)\n",
    "print(best_tree_clf)\n",
    "results = results.append({'clf': best_tree_clf, 'best_acc': tree_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And finally**, we predict the unknown label for the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67029, 79), (28645, 79))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = results.clf.iloc[0].predict(XX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we do is generating a file that should be *submitted* on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.VisitNumber, yy)), columns=[\"VisitNumber\", \"TripType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"../data/submission.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosas para hacer:\n",
    "##### Eliminar los Nan\n",
    "##### Corroborar que los triptype para los registros de la misma compra dan igual\n",
    "##### Relaci√≥n entre finenumber y upc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mentoria] *",
   "language": "python",
   "name": "conda-env-mentoria-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
