{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplodatos Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present this peace of code to create the baseline for the competition, and as an example of how to deal with these kind of problems. The main goals are that you:\n",
    "\n",
    "1. Learn\n",
    "1. Try different models and see which one fits the best the given data\n",
    "1. Get a higher score than the given one in the current baseline example\n",
    "1. Try to get the highest score in the class :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-060e5a3fb5de>:9: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "# Import the required packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_rows', 20000)\n",
    "pd.set_option('display.max_columns', 100000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the *original* dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TripType                 1.000000\n",
       "VisitNumber              1.000000\n",
       "Weekday                  1.000000\n",
       "Upc                      0.993710\n",
       "ScanCount                1.000000\n",
       "DepartmentDescription    0.997856\n",
       "FinelineNumber           0.993710\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of non-missing values in each column\n",
    "original_df.count() / len(original_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are `nan`s in the column, let us find them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df['num_of_products_for_VisitNumber']= original_df['VisitNumber'].apply(lambda x:products_per_visit.get(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flot_to_str(obj):\n",
    "    \"\"\"\n",
    "    Convert Upc code from float to string.\n",
    "    Use this function by applying lambda\n",
    "    Parameters: \"Upc\" column of DataFrame\n",
    "    Return:string converted Upc removing dot\n",
    "    \"\"\"\n",
    "    while obj != 'np.nan':\n",
    "        obj = str(obj).split('.')[0]\n",
    "        if len(obj) == 10:\n",
    "            obj = obj + '0'\n",
    "        elif len(obj) == 4:\n",
    "            obj = obj + '0000000' \n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company(upcData):\n",
    "    \"\"\"\n",
    "    Return company code from given Upc code.\n",
    "    Parameters:'Upc' column of DataFrame\n",
    "    Return: company code\n",
    "    \"\"\"\n",
    "    try:\n",
    "        code = upcData[: 6]\n",
    "        if code == '000000':\n",
    "            return x[-5]\n",
    "        return code\n",
    "    except:\n",
    "        return -9999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prodct(upcData):\n",
    "    \"\"\"\n",
    "    Return company code from given Upc code.\n",
    "    Parameters:'Upc' column of DataFrame\n",
    "    Return: company code\n",
    "    \"\"\"\n",
    "    try:\n",
    "        code = upcData[6 :]\n",
    "        return code\n",
    "    except:\n",
    "        return -9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### **Now we create the function...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data_fname, test_data_fname):\n",
    "    df_train = pd.read_csv(train_data_fname)\n",
    "    df_train['is_train_set'] = 1\n",
    "    df_test = pd.read_csv(test_data_fname)\n",
    "    df_test['is_train_set'] = 0\n",
    "    \n",
    "    # drop nan rows\n",
    "    df_train.loc[df_train.Upc.isna(), \"Upc\"] = 0\n",
    "    df_test.loc[df_test.Upc.isna(), \"Upc\"] = 0\n",
    "   \n",
    "    \n",
    "    # we  get the TripType for the train set. To do that, we group by VisitNumber and\n",
    "    # then we get the max (or min or avg)\n",
    "    y = df_train.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).max().TripType\n",
    "\n",
    "    # we remove the TripType now, and concat training and testing data\n",
    "    # the concat is done so that we have the same columns for both datasets\n",
    "    # after one-hot encoding\n",
    "    df_train = df_train.drop(\"TripType\", axis=1)\n",
    "    df = pd.concat([df_train, df_test])\n",
    "\n",
    "    # create new columns based on upc\n",
    "    products_per_visit= dict(df.groupby(['VisitNumber'])['Upc'].count())\n",
    "    df['num_of_products_for_VisitNumber']= df['VisitNumber'].apply(lambda x:products_per_visit.get(x,0))\n",
    "    df['company_code'] = df['Upc'].apply(flot_to_str).apply(company).apply(pd.to_numeric)\n",
    "    df['company_code_cat'] = pd.cut(df['company_code'],bins=50,labels=False)\n",
    "    \n",
    "    # create the column fineline categoric\n",
    "    df['FinelineCat'] = pd.cut(df['FinelineNumber'],bins=50,labels=False)\n",
    "    \n",
    "    # drop the columns we won't use \n",
    "    df = df.drop([\"Upc\", \"FinelineNumber\", \"company_code\"], axis=1)\n",
    "\n",
    "    # one-hot encoding for the DepartmentDescription\n",
    "    df = pd.get_dummies(df, columns=[\"DepartmentDescription\", \"num_of_products_for_VisitNumber\", \"FinelineCat\"], dummy_na=True)\n",
    "\n",
    "    # now we add the groupby values\n",
    "    df = df.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).sum()\n",
    "    \n",
    "    # finally, we do one-hot encoding for the Weekday\n",
    "    df = pd.get_dummies(df, columns=[\"Weekday\"], dummy_na=True)\n",
    "\n",
    "    # get train and test back\n",
    "    df_train = df[df.is_train_set != 0]\n",
    "    df_test = df[df.is_train_set == 0]\n",
    "    \n",
    "    X = df_train.drop([\"is_train_set\"], axis=1)\n",
    "    yy = None\n",
    "    XX = df_test.drop([\"is_train_set\"], axis=1)\n",
    "\n",
    "    return X, y, XX, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, XX, yy = transform_data('../data/train.csv',\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67029, 230)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training dataset into train and \"validation\" \n",
    "# (we won't be using validation set in this example, because of the cross-validation;\n",
    "# but it could be useful for you depending on your approach)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('linearsvc', LinearSVC(random_state=0, tol=1e-05))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "#X, y = make_classification(n_features=4, random_state=0)\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "                     LinearSVC(random_state=0, tol=1e-5))\n",
    "clf.fit(X_train, y_train)\n",
    "#Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "#                ('linearsvc', LinearSVC(random_state=0, tol=1e-05))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.79      0.97      0.87       794\n",
      "           4       0.61      0.40      0.49        67\n",
      "           5       0.78      0.86      0.82       976\n",
      "           6       0.73      0.84      0.78       260\n",
      "           7       0.66      0.71      0.68      1205\n",
      "           8       0.72      0.90      0.80      2540\n",
      "           9       0.65      0.79      0.71      1968\n",
      "          12       0.45      0.10      0.17        49\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.50      0.33      0.40       204\n",
      "          18       0.54      0.40      0.46       121\n",
      "          19       0.64      0.43      0.51        75\n",
      "          20       0.61      0.55      0.57       130\n",
      "          21       0.61      0.59      0.60       155\n",
      "          22       0.57      0.41      0.48       206\n",
      "          23       0.67      0.77      0.71        26\n",
      "          24       0.61      0.57      0.59       581\n",
      "          25       0.69      0.80      0.74       793\n",
      "          26       0.52      0.37      0.43       104\n",
      "          27       0.64      0.59      0.61       164\n",
      "          28       0.63      0.51      0.56       112\n",
      "          29       0.59      0.36      0.45        83\n",
      "          30       0.57      0.47      0.51       232\n",
      "          31       0.63      0.75      0.68       123\n",
      "          32       0.73      0.75      0.74       433\n",
      "          33       0.61      0.59      0.60       275\n",
      "          34       0.55      0.52      0.54       134\n",
      "          35       0.60      0.62      0.61       411\n",
      "          36       0.59      0.65      0.62       635\n",
      "          37       0.66      0.51      0.58       617\n",
      "          38       0.58      0.40      0.48       604\n",
      "          39       0.58      0.61      0.59      2103\n",
      "          40       0.73      0.83      0.78      1217\n",
      "          41       0.33      0.02      0.03       124\n",
      "          42       0.48      0.16      0.25       371\n",
      "          43       0.00      0.00      0.00       168\n",
      "          44       0.35      0.09      0.15       249\n",
      "         999       0.93      0.71      0.80      1799\n",
      "\n",
      "    accuracy                           0.69     20109\n",
      "   macro avg       0.58      0.52      0.54     20109\n",
      "weighted avg       0.67      0.69      0.67     20109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_valid, clf.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And finally**, we predict the unknown label for the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67029, 230), (28645, 230))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = clf.predict(XX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we do is generating a file that should be *submitted* on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.VisitNumber, yy)), columns=[\"VisitNumber\", \"TripType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_manu_SVC.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mentoria] *",
   "language": "python",
   "name": "conda-env-mentoria-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
