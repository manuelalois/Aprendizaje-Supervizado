{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-1e9fd325078d>:13: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "# Import the required packages\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.utils import resample\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "pd.set_option('display.max_rows', 20000)\n",
    "pd.set_option('display.max_columns', 20000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data_fname, test_data_fname):\n",
    "    df_train = pd.read_csv(train_data_fname)\n",
    "    df_train['is_train_set'] = 1\n",
    "    df_test = pd.read_csv(test_data_fname)\n",
    "    df_test['is_train_set'] = 0\n",
    "    \n",
    "    # Comienzo con los datos de TRAIN\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # Elimino los datos que tienen Nan en el Department Description\n",
    "    clean_df = df_train.dropna(subset=['DepartmentDescription'])\n",
    "\n",
    "    # Los datos que tienen Nan en Upc son todos de Pharmacy RX\n",
    "    # Luego los completo con esos valores, obtenidos por inspecci√≥n\n",
    "    clean_df.loc[clean_df.Upc.isna(), \"FinelineNumber\"] = 4822\n",
    "    clean_df.loc[clean_df.Upc.isna(), \"Upc\"] = 30169183702\n",
    "    \n",
    "#    unique_tt = df_train.TripType.unique()\n",
    "#    lista_df = []\n",
    "#    for i in unique_tt:\n",
    "#        iterator = clean_df[clean_df.TripType == i]\n",
    "#        max = iterator.Upc.value_counts().idxmax()\n",
    "#        iterator.Upc = max\n",
    "#        lista_df.append(iterator)\n",
    "\n",
    "    unique_vn = df_train.VisitNumber.unique()\n",
    "    lista_df = []\n",
    "    for i in unique_vn:\n",
    "        iterator = clean_df[clean_df.VisitNumber == i]\n",
    "        max = iterator.Upc.max()\n",
    "        iterator.Upc = max\n",
    "        lista_df.append(iterator)\n",
    "\n",
    "\n",
    "    df_total = pd.concat(lista_df)\n",
    "    df_total = df_total.drop([\"FinelineNumber\"], axis=1)\n",
    "    y = df_total.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).max().TripType\n",
    "\n",
    "    df_total = df_total.drop(\"TripType\", axis=1)\n",
    "    \n",
    "    # VISITNUMBER, DEPARTMENT, UPC, WEEKDAY\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    df_test.loc[df_test.DepartmentDescription.isna(), \"Upc\"] = 0\n",
    "    df_test.loc[df_test.Upc.isna(), \"Upc\"] = 30169183702\n",
    "    unique_vn = df_test.VisitNumber.unique()\n",
    "    lista_df = []\n",
    "    for i in unique_vn:\n",
    "        iterator = df_test[df_test.VisitNumber == i]\n",
    "        max = iterator.Upc.max()\n",
    "        iterator.Upc = max\n",
    "        lista_df.append(iterator)\n",
    "\n",
    "    test_total = pd.concat(lista_df)\n",
    "    \n",
    "    test_total = test_total.drop([\"FinelineNumber\"], axis=1)\n",
    "    \n",
    "    # VISITNUMBER, DEPARTMENT, UPC, WEEKDAY\n",
    "    \n",
    "    temp_concat = pd.concat([df_total, test_total])\n",
    "    temp_concat = pd.get_dummies(temp_concat, columns=[\"DepartmentDescription\"], dummy_na=True)\n",
    "    temp_concat = temp_concat.groupby([\"VisitNumber\", \"Weekday\", \"Upc\"], as_index=False).sum()\n",
    "#    temp_concat.loc[temp_concat.ScanCount<0, \"ScanCount\"] = 0\n",
    "    \n",
    "    temp_concat = pd.get_dummies(temp_concat, columns=[\"Weekday\"], dummy_na=True)\n",
    "    \n",
    "    df_train = temp_concat[temp_concat.is_train_set != 0]\n",
    "    df_test = temp_concat[temp_concat.is_train_set == 0]\n",
    "\n",
    "    X = df_train.drop([\"is_train_set\"], axis=1)\n",
    "    yy = None\n",
    "    XX = df_test.drop([\"is_train_set\"], axis=1)\n",
    "\n",
    "\n",
    "    return X, y, XX, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, XX, yy = transform_data(\"../data/train.csv\", \"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.92      0.95      0.94       785\n",
      "           4       0.38      0.12      0.19        82\n",
      "           5       0.71      0.83      0.76       935\n",
      "           6       0.76      0.74      0.75       260\n",
      "           7       0.66      0.67      0.66      1173\n",
      "           8       0.78      0.88      0.83      2525\n",
      "           9       0.73      0.78      0.75      2038\n",
      "          12       0.40      0.06      0.11        65\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.55      0.38      0.45       205\n",
      "          18       0.57      0.31      0.40       126\n",
      "          19       0.56      0.31      0.40        91\n",
      "          20       0.57      0.50      0.54       115\n",
      "          21       0.72      0.63      0.67       142\n",
      "          22       0.46      0.29      0.36       198\n",
      "          23       0.64      0.56      0.60        25\n",
      "          24       0.59      0.53      0.56       538\n",
      "          25       0.61      0.75      0.67       741\n",
      "          26       0.45      0.27      0.34        94\n",
      "          27       0.72      0.58      0.64       177\n",
      "          28       0.38      0.25      0.30        79\n",
      "          29       0.30      0.09      0.14        87\n",
      "          30       0.47      0.32      0.38       220\n",
      "          31       0.70      0.75      0.72       123\n",
      "          32       0.63      0.70      0.66       401\n",
      "          33       0.66      0.51      0.57       280\n",
      "          34       0.71      0.51      0.59       168\n",
      "          35       0.54      0.53      0.54       451\n",
      "          36       0.55      0.65      0.60       612\n",
      "          37       0.62      0.43      0.51       647\n",
      "          38       0.51      0.32      0.39       605\n",
      "          39       0.50      0.73      0.59      2109\n",
      "          40       0.73      0.93      0.82      1305\n",
      "          41       0.00      0.00      0.00       123\n",
      "          42       0.36      0.08      0.12       386\n",
      "          43       0.00      0.00      0.00       192\n",
      "          44       0.42      0.02      0.04       240\n",
      "         999       0.96      0.84      0.90      1732\n",
      "\n",
      "    accuracy                           0.68     20076\n",
      "   macro avg       0.55      0.47      0.49     20076\n",
      "weighted avg       0.66      0.68      0.66     20076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import ensemble\n",
    "\n",
    "clf = ensemble.RandomForestClassifier(random_state=2)\n",
    "clf.fit(X_train, y_train);\n",
    "#rf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n",
    "#predictions = clf.predict(X_train)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_valid, clf.predict(X_valid)))\n",
    "\n",
    "#param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10], \"min_samples_split\" : [2, 4, 10, 12, 16], \"n_estimators\": [50, 100, 400, 700, 1000]}\n",
    "\n",
    "#tree_clf = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "\n",
    "#tree_clf.fit(X_train, y_train)\n",
    "#best_tree_clf = tree_clf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.78      0.92      0.84       785\n",
      "           4       0.00      0.00      0.00        82\n",
      "           5       0.67      0.84      0.75       935\n",
      "           6       0.55      0.60      0.57       260\n",
      "           7       0.65      0.66      0.65      1173\n",
      "           8       0.61      0.88      0.72      2525\n",
      "           9       0.64      0.71      0.67      2038\n",
      "          12       0.45      0.08      0.13        65\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.44      0.39      0.41       205\n",
      "          18       0.40      0.33      0.36       126\n",
      "          19       0.38      0.03      0.06        91\n",
      "          20       0.41      0.50      0.45       115\n",
      "          21       0.52      0.62      0.57       142\n",
      "          22       0.34      0.42      0.38       198\n",
      "          23       0.17      0.16      0.16        25\n",
      "          24       0.54      0.66      0.59       538\n",
      "          25       0.61      0.81      0.69       741\n",
      "          26       0.39      0.40      0.40        94\n",
      "          27       0.61      0.60      0.61       177\n",
      "          28       0.30      0.39      0.34        79\n",
      "          29       0.00      0.00      0.00        87\n",
      "          30       0.38      0.40      0.39       220\n",
      "          31       0.58      0.77      0.66       123\n",
      "          32       0.61      0.68      0.64       401\n",
      "          33       0.56      0.57      0.56       280\n",
      "          34       0.57      0.49      0.53       168\n",
      "          35       0.48      0.41      0.44       451\n",
      "          36       0.55      0.65      0.60       612\n",
      "          37       0.58      0.60      0.59       647\n",
      "          38       0.45      0.38      0.41       605\n",
      "          39       0.60      0.34      0.44      2109\n",
      "          40       0.73      0.83      0.78      1305\n",
      "          41       0.29      0.02      0.03       123\n",
      "          42       0.44      0.16      0.24       386\n",
      "          43       0.00      0.00      0.00       192\n",
      "          44       0.56      0.06      0.11       240\n",
      "         999       0.91      0.67      0.77      1732\n",
      "\n",
      "    accuracy                           0.62     20076\n",
      "   macro avg       0.47      0.45      0.44     20076\n",
      "weighted avg       0.61      0.62      0.60     20076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Best Random Forest accuracy: ', tree_clf.best_score_)\n",
    "print(best_tree_clf)\n",
    "results = results.append({'clf': best_tree_clf, 'best_acc': tree_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((66917, 80), (28645, 80))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yy = results.clf.iloc[0].predict(XX)\n",
    "yy = clf.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.VisitNumber, yy)), columns=[\"VisitNumber\", \"TripType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_randomForest.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mentoria] *",
   "language": "python",
   "name": "conda-env-mentoria-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
