{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplodatos Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present this peace of code to create the baseline for the competition, and as an example of how to deal with these kind of problems. The main goals are that you:\n",
    "\n",
    "1. Learn\n",
    "1. Try different models and see which one fits the best the given data\n",
    "1. Get a higher score than the given one in the current baseline example\n",
    "1. Try to get the highest score in the class :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-a6820bab1e6a>:11: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "# Import the required packages\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "pd.set_option('display.max_rows', 20000)\n",
    "pd.set_option('display.max_columns', 20000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the *original* dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data_fname, test_data_fname):\n",
    "    df_train = pd.read_csv(train_data_fname)\n",
    "    df_train['is_train_set'] = 1\n",
    "    df_test = pd.read_csv(test_data_fname)\n",
    "    df_test['is_train_set'] = 0\n",
    "    \n",
    "    # Comenzamos con los datos de TRAIN\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # Eliminamos los datos que tienen Nan en el Department Description\n",
    "    clean_df = df_train.dropna(subset=['DepartmentDescription'])\n",
    "\n",
    "    # Los datos que tienen Nan en Upc son todos de Pharmacy RX\n",
    "    # Luego los completamos con esos valores, obtenidos por inspección\n",
    "    clean_df.loc[clean_df.Upc.isna(), \"FinelineNumber\"] = 4822\n",
    "    clean_df.loc[clean_df.Upc.isna(), \"Upc\"] = 30169183702\n",
    "    \n",
    "#    unique_tt = df_train.TripType.unique()\n",
    "#    lista_df = []\n",
    "#    for i in unique_tt:\n",
    "#        iterator = clean_df[clean_df.TripType == i]\n",
    "#        max = iterator.Upc.value_counts().idxmax()\n",
    "#        iterator.Upc = max\n",
    "#        lista_df.append(iterator)\n",
    "\n",
    "    unique_vn = df_train.VisitNumber.unique()\n",
    "    lista_df = []\n",
    "    for i in unique_vn:\n",
    "        iterator = clean_df[clean_df.VisitNumber == i]\n",
    "        min = iterator.Upc.min()\n",
    "        iterator.Upc = min\n",
    "        lista_df.append(iterator)\n",
    "\n",
    "\n",
    "    df_total = pd.concat(lista_df)\n",
    "    df_total = df_total.drop([\"FinelineNumber\"], axis=1)\n",
    "    y = df_total.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).max().TripType\n",
    "\n",
    "    df_total = df_total.drop(\"TripType\", axis=1)\n",
    "    \n",
    "    # VISITNUMBER, DEPARTMENT, UPC, WEEKDAY\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    df_test.loc[df_test.DepartmentDescription.isna(), \"Upc\"] = 0\n",
    "    df_test.loc[df_test.Upc.isna(), \"Upc\"] = 30169183702\n",
    "    unique_vn = df_test.VisitNumber.unique()\n",
    "    lista_df = []\n",
    "    for i in unique_vn:\n",
    "        iterator = df_test[df_test.VisitNumber == i]\n",
    "        min = iterator.Upc.min()\n",
    "        iterator.Upc = min\n",
    "        lista_df.append(iterator)\n",
    "\n",
    "    test_total = pd.concat(lista_df)\n",
    "    \n",
    "    test_total = test_total.drop([\"FinelineNumber\"], axis=1)\n",
    "    \n",
    "    # VISITNUMBER, DEPARTMENT, UPC, WEEKDAY\n",
    "    \n",
    "    temp_concat = pd.concat([df_total, test_total])\n",
    "    temp_concat = pd.get_dummies(temp_concat, columns=[\"DepartmentDescription\"], dummy_na=True)\n",
    "    temp_concat = temp_concat.groupby([\"VisitNumber\", \"Weekday\", \"Upc\"], as_index=False).sum()\n",
    "    \n",
    "    temp_concat = pd.get_dummies(temp_concat, columns=[\"Weekday\"], dummy_na=True)\n",
    "    \n",
    "    df_train = temp_concat[temp_concat.is_train_set != 0]\n",
    "    df_test = temp_concat[temp_concat.is_train_set == 0]\n",
    "\n",
    "    X = df_train.drop([\"is_train_set\"], axis=1)\n",
    "    yy = None\n",
    "    XX = df_test.drop([\"is_train_set\"], axis=1)\n",
    "\n",
    "\n",
    "    return X, y, XX, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, XX, yy = transform_data(\"../data/train.csv\", \"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training dataset into train and \"validation\" \n",
    "# (we won't be using validation set in this example, because of the cross-validation;\n",
    "# but it could be useful for you depending on your approach)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results dataframe is used to store the computed results\n",
    "results = pd.DataFrame(columns=('clf', 'best_acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'criterion': ('gini', 'entropy'),\n",
       "                         'min_samples_leaf': (1, 2, 5),\n",
       "                         'min_samples_split': (2, 3, 5, 10, 50, 100)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use a DesicionTree to classify and GridSearch to determine the parameters\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree_param = {'criterion':('gini', 'entropy'), 'min_samples_leaf':(1, 2, 5),\n",
    "              'min_samples_split':(2, 3, 5, 10, 50, 100)}\n",
    "tree = DT(random_state=42)\n",
    "tree_clf = GridSearchCV(tree, tree_param, cv=3, scoring='accuracy') #scoring='balanced_accuracy')\n",
    "tree_clf.fit(X_train, y_train)\n",
    "best_tree_clf = tree_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree accuracy:  0.6420445607832895\n",
      "DecisionTreeClassifier(min_samples_leaf=2, min_samples_split=100,\n",
      "                       random_state=42)\n",
      "The best classifier so far is: \n",
      "DecisionTreeClassifier(min_samples_leaf=2, min_samples_split=100,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print('Best Decision Tree accuracy: ', tree_clf.best_score_)\n",
    "print(best_tree_clf)\n",
    "results = results.append({'clf': best_tree_clf, 'best_acc': tree_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And finally**, we predict the unknown label for the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((66917, 80), (28645, 80))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = results.clf.iloc[0].predict(XX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we do is generating a file that should be *submitted* on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.VisitNumber, yy)), columns=[\"VisitNumber\", \"TripType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"../data/submission.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosas para hacer:\n",
    "##### Eliminar los Nan\n",
    "##### Corroborar que los triptype para los registros de la misma compra dan igual\n",
    "##### Relación entre finenumber y upc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
